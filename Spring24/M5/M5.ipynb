{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOVuY8vET8o5"
      },
      "source": [
        "# CMPS 4010\n",
        "## Milestone 5: Unrealized Volatility Prediction\n",
        "### By Alex Olteanu and Shira Rozenthal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCqMjbuQ1yhB"
      },
      "source": [
        "### Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5oTL5_y11GZ"
      },
      "source": [
        "**IN PROGRESS**\n",
        "- Create M5.ipynb: Remove irrelevant code, focus on preprocessing data for feature engineering.\n",
        "\n",
        "- Feature Engineering: Implement features Shira suggested; explore others with high correlation.\n",
        "\n",
        "- Experiment: Test various feature combinations, aim for lowest test error.\n",
        "\n",
        "- Research: Explore many-to-one, sequential, and time-series models for handling large datasets without data loss due to flattening.\n",
        "\n",
        "- Understand: Grasp how these models function and how feature engineering effects differing models. Ex: From time series to single model applications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6gZlJILpStt"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDK1YOIGnWDN",
        "outputId": "a3410984-14ff-4d15-96b5-f6d2d51047a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/alexolteanu/Desktop/Spring-2024/CS Capstone II/Kaggle Data/optiver-realized-volatility-prediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexolteanu/Library/Python/3.12/lib/python/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd /Users/alexolteanu/Desktop/Spring-2024/CS Capstone II/Kaggle Data/optiver-realized-volatility-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/shirarozenthal/Documents/CS/Git/optiver-realized-volatility-prediction\n"
          ]
        }
      ],
      "source": [
        "%cd /Users/shirarozenthal/Documents/CS/Git/optiver-realized-volatility-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gLeqVlfgpK1C"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# Test\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, minmax_scale\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Parallel processing\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Set matplotlib to display inline and pandas option\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oBkUzxmtzAl"
      },
      "source": [
        "### Tutorial Notebook Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kU_S9kcjGc-H"
      },
      "outputs": [],
      "source": [
        "# Load train data\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "# Load test data\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Initialize stock_id\n",
        "stock_id = 0\n",
        "\n",
        "# Load book data\n",
        "book_example = pd.read_parquet('book_train.parquet/stock_id=0')\n",
        "\n",
        "# Load trade data\n",
        "trade_example = pd.read_parquet('trade_train.parquet/stock_id=0')\n",
        "\n",
        "# Reassign book_example to only include stock_id 0\n",
        "book_example = book_example[book_example['time_id']==5]\n",
        "\n",
        "# Create stock_id column in book_example\n",
        "book_example.loc[:,'stock_id'] = stock_id\n",
        "\n",
        "# Reassign trade_example to only include stock_id 0\n",
        "trade_example = trade_example[trade_example['time_id']==5]\n",
        "\n",
        "# Create stock_id column in trade_example\n",
        "trade_example.loc[:,'stock_id'] = stock_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtQ6mroFuHKJ",
        "outputId": "47187cbc-912c-4a4f-e20e-1684ec0bf052"
      },
      "outputs": [],
      "source": [
        "# Generate a WAP feature for example book df\n",
        "# WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1)\n",
        "book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n",
        "                                book_example['ask_price1'] * book_example['bid_size1']) / (\n",
        "                                       book_example['bid_size1']+ book_example['ask_size1'])\n",
        "\n",
        "# Define function for computing log returns\n",
        "# Log return = log(current price / previous price)\n",
        "def log_return(list_stock_prices):\n",
        "    return np.log(list_stock_prices).diff()\n",
        "\n",
        "# Generate a log return column for book_example df\n",
        "# Takes the log return of the current row and previous row \n",
        "# Row zero omitted because it cannot be compared to a previous time entry using ~ operator\n",
        "book_example.loc[:,'log_return'] = log_return(book_example['wap'])\n",
        "book_example = book_example[~book_example['log_return'].isnull()]\n",
        "\n",
        "# Define a function to compute realized volatility using the log returns in a time bucket\n",
        "# Computed by taking the square root of the sum of squared log returns\n",
        "# # Realized volatility = sqrt(sum(log returns^2))\n",
        "def realized_volatility(series_log_return):\n",
        "    return np.sqrt(np.sum(series_log_return**2))\n",
        "\n",
        "realized_vol = realized_volatility(book_example['log_return'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DM1-Xuuf-Q",
        "outputId": "454a8390-fdf1-4ae0-a877-8e275dc4b690"
      },
      "outputs": [],
      "source": [
        "# Create a list of all file paths within book training parquet file\n",
        "list_order_book_file_train = glob.glob('book_train.parquet/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0nxgei2ruiey"
      },
      "outputs": [],
      "source": [
        "# Define a function for computing the realitized volatiltiy for each time bucket for a specific stock\n",
        "def realized_volatility_per_time_id(file_path, prediction_column_name):\n",
        "    # Load the parquet file for a specific stock into a DataFrame\n",
        "    df_book_data = pd.read_parquet(file_path)\n",
        "\n",
        "    # Compute the Weighted Average Price (WAP) using bid and ask prices and sizes\n",
        "    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n",
        "                                      df_book_data['bid_size1']+ df_book_data['ask_size1'])\n",
        "\n",
        "    # Calculate the log returns of WAP for each 'time_id'\n",
        "    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
        "\n",
        "    # Remove rows with NaN values in the 'log_return' column\n",
        "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
        "\n",
        "    # Compute the realized volatility for each 'time_id' based on the log returns\n",
        "    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
        "\n",
        "    # Rename the 'log_return' column to the provided prediction_column_name\n",
        "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n",
        "\n",
        "    # Extract the stock_id from the file_path\n",
        "    stock_id = file_path.split('=')[1]\n",
        "\n",
        "    # Create a 'row_id' column combining the stock_id and time_id\n",
        "    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
        "\n",
        "    return df_realized_vol_per_stock[['row_id',prediction_column_name]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgKxuJqfungc",
        "outputId": "54ff55fb-bb6a-442d-ff94-fc1d979c13da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
            "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_19161/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n"
          ]
        }
      ],
      "source": [
        "def past_realized_volatility_per_stock(list_file,prediction_column_name):\n",
        "    # Initialize an empty DataFrame to store the results for all stocks\n",
        "    df_past_realized = pd.DataFrame()\n",
        "\n",
        "    # Loop through each file in the provided list (each file corresponds to a stock's data)\n",
        "    for file in list_file:\n",
        "        # Compute the realized volatility for the current stock using the function 'realized_volatility_per_time_id'\n",
        "        # This function returns the realized volatility for each 'time_id' of the current stock\n",
        "        df_single_stock_realized_vol = realized_volatility_per_time_id(file, prediction_column_name)\n",
        "\n",
        "        # Concatenate the results for the current stock with the aggregated results\n",
        "        df_past_realized = pd.concat([df_past_realized, df_single_stock_realized_vol])\n",
        "\n",
        "    # Return the aggregated results for all stocks\n",
        "    return df_past_realized\n",
        "\n",
        "# Calculate the realized volatility for all stocks in the training data\n",
        "# The list 'list_order_book_file_train' contains file paths for all stocks in the training set\n",
        "df_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train, prediction_column_name='pvol')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W-UeQgpaupAW"
      },
      "outputs": [],
      "source": [
        "# Create a new column 'row_id' in the 'train' dataframe. This column is a combination of the 'stock_id' and 'time_id' columns.\n",
        "# The two values are separated by a '-' and both are converted to string type to facilitate concatenation.\n",
        "train_mod = pd.read_csv('train.csv')\n",
        "\n",
        "train_mod['row_id'] = train['stock_id'].astype(str) + '-' + train_mod['time_id'].astype(str)\n",
        "\n",
        "# Update the 'train' dataframe to keep only the 'row_id' and 'target' columns.\n",
        "train_mod = train_mod[['row_id','target']]\n",
        "\n",
        "# Merge the 'train' dataframe with the 'df_past_realized_train' dataframe.\n",
        "# The merging is based on the 'row_id' column, which is common between the two dataframes.\n",
        "# This is a left merge, which means all the rows from the 'train' dataframe will be retained and corresponding\n",
        "# values from 'df_past_realized_train' will be added wherever there's a match based on 'row_id'.\n",
        "# If there's no match for a particular 'row_id' in 'df_past_realized_train', NaN values will be filled for 'pred' column.\n",
        "df_joined = train_mod.merge(df_past_realized_train[['row_id','pvol']], on = ['row_id'], how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vEjSs4lDwf9L",
        "outputId": "af34bd80-c77f-4676-981b-e5c47c2d8bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance of the naive prediction: R2 score: 0.628, RMSPE: 0.341\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Define a function to calculate the Root Mean Squared Percentage Error (RMSPE)\n",
        "def rmspe(y_true, y_pred):\n",
        "    # The formula for RMSPE is the square root of the average of squared percentage errors.\n",
        "    # The percentage error is calculated as (actual - predicted) / actual, squared to penalize larger errors.\n",
        "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
        "\n",
        "# Calculate the R^2 score using the true target values and the predicted values from the 'df_joined' dataframe.\n",
        "# The R^2 score measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
        "# It provides a measure of how well the observed outcomes are replicated by the model.\n",
        "R2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pvol']),3)\n",
        "\n",
        "# Calculate the RMSPE using the true target values and the predicted values from the 'df_joined' dataframe.\n",
        "RMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pvol']),3)\n",
        "\n",
        "# Print out the calculated R^2 score and RMSPE.\n",
        "print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLeoQqC8mJa1"
      },
      "source": [
        "### Reversing Time-ID order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "399MsEMwnBQa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:33: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:33: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/var/folders/g2/qbz891654sj8hstpjwf0pr7r0000gn/T/ipykernel_9680/3112154199.py:33: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  .eval('stock_id = book_path.str.extract(\"stock_id=(\\d+)\").astype(\"int\")', engine='python')\n"
          ]
        }
      ],
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    s = time.time()\n",
        "    yield\n",
        "    e = time.time() - s\n",
        "    print(f\"[{name}] {e:.3f}sec\")\n",
        "\n",
        "\n",
        "def calc_price2(df):\n",
        "    tick = sorted(np.diff(sorted(np.unique(df.values.flatten()))))[0]\n",
        "    return 0.01 / tick\n",
        "\n",
        "def calc_prices(r):\n",
        "    df = pd.read_parquet(r.book_path, columns=['time_id', 'ask_price1', 'ask_price2', 'bid_price1', 'bid_price2'])\n",
        "    df = df.set_index('time_id')\n",
        "    df = df.groupby(level='time_id').apply(calc_price2).to_frame('price').reset_index()\n",
        "    df['stock_id'] = r.stock_id\n",
        "    return df\n",
        "\n",
        "def sort_manifold(df, clf):\n",
        "    df_ = df.set_index('time_id')\n",
        "    df_ = pd.DataFrame(minmax_scale(df_.fillna(df_.mean())))\n",
        "\n",
        "    X_compoents = clf.fit_transform(df_)\n",
        "\n",
        "    dft = df.reindex(np.argsort(X_compoents[:,0])).reset_index(drop=True)\n",
        "    return np.argsort(X_compoents[:, 0]), X_compoents\n",
        "\n",
        "def reconstruct_time_id_order():\n",
        "    with timer('load files'):\n",
        "        df_files = pd.DataFrame(\n",
        "            {'book_path': glob.glob('book_train.parquet/**/*.parquet')}) \\\n",
        "            .eval('stock_id = book_path.str.extract(\"stock_id=(\\d+)\").astype(\"int\")', engine='python')\n",
        "\n",
        "    with timer('calc prices'):\n",
        "        df_prices = pd.concat(Parallel(n_jobs=4, verbose=51)(delayed(calc_prices)(r) for _, r in df_files.iterrows()))\n",
        "        df_prices = df_prices.pivot('time_id', 'stock_id', 'price')\n",
        "        df_prices.columns = [f'stock_id={i}' for i in df_prices.columns]\n",
        "        df_prices = df_prices.reset_index(drop=False)\n",
        "\n",
        "    with timer('t-SNE(400) -> 50'):\n",
        "        clf = TSNE(n_components=1, perplexity=400, random_state=0, n_iter=2000)\n",
        "        order, X_compoents = sort_manifold(df_prices, clf)\n",
        "\n",
        "        clf = TSNE(n_components=1, perplexity=50, random_state=0, init=X_compoents, n_iter=2000, method='exact')\n",
        "        order, X_compoents = sort_manifold(df_prices, clf)\n",
        "\n",
        "        df_ordered = df_prices.reindex(order).reset_index(drop=True)\n",
        "        if df_ordered['stock_id=61'].iloc[0] > df_ordered['stock_id=61'].iloc[-1]:\n",
        "            df_ordered = df_ordered.reindex(df_ordered.index[::-1]).reset_index(drop=True)\n",
        "\n",
        "    # AMZN\n",
        "    plt.plot(df_ordered['stock_id=61'])\n",
        "\n",
        "    return df_ordered[['time_id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiVyA70iob3P",
        "outputId": "3b4dfa09-862c-4e31-f67b-65bbbea491f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[load files] 0.014sec\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<unknown>:1: SyntaxWarning: invalid escape sequence '\\d'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:   14.2s\n",
            "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:   14.7s\n",
            "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:   14.8s\n",
            "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=4)]: Done 108 out of 112 | elapsed:   15.5s remaining:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done 112 out of 112 | elapsed:   15.9s finished\n",
            "[calc prices] 16.031sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/g2/qbz891654sj8hstpjwf0pr7r0000gn/T/ipykernel_9680/3112154199.py:37: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
            "  df_prices = df_prices.pivot('time_id', 'stock_id', 'price')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[t-SNE(400) -> 50] 381.247sec\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_ordered = reconstruct_time_id_order()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvuDDcP307Xo"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Neighboring Volatility Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list of all file paths within book training parquet file\n",
        "list_order_book_file_train = glob.glob('book_train.parquet/*')\n",
        "\n",
        "# Create a list of all file paths within trade training parquet file\n",
        "list_order_trade_file_train = glob.glob('trade_train.parquet/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "master = df_joined\n",
        "\n",
        "# \n",
        "master = master.rename(columns={'pvol': 'realized_vol'})\n",
        "\n",
        "# Set the 'order' column of df_ordered to be its index values\n",
        "df_ordered['order'] = df_ordered.index "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge 'train' DataFrame with 'df_ordered' based on the 'time_id' column\n",
        "# This is a left join, which means all rows from 'train' will be kept, \n",
        "# along with matched rows from 'df_ordered'\n",
        "merged_df = pd.merge(train, df_ordered, on='time_id', how='left')\n",
        "\n",
        "# Sort the merged DataFrame first by 'stock_id' and then by 'order'\n",
        "merged_df.sort_values(by=['stock_id', 'order'], inplace=True)\n",
        "\n",
        "# Create a new 'row_id' column by concatenating 'stock_id' and 'time_id' as strings\n",
        "merged_df['row_id'] = merged_df['stock_id'].astype(str) + '-' + merged_df['time_id'].astype(str)\n",
        "\n",
        "# Reorder columns so that 'row_id' is the first column, and retain all other columns\n",
        "cols = ['row_id'] + [col for col in merged_df.columns if col != 'row_id']\n",
        "df_merged = merged_df[cols]\n",
        "\n",
        "# Drop 'stock_id' and 'time_id' columns from the DataFrame\n",
        "df_merged = df_merged.drop(['stock_id', 'time_id'], axis=1)\n",
        "\n",
        "# Swap the positions of the second and third columns in the DataFrame\n",
        "cols = df_merged.columns.tolist()\n",
        "cols[1], cols[2] = cols[2], cols[1]\n",
        "df_merged = df_merged[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge 'master' DataFrame with 'df_merged' on 'row_id', using a right join\n",
        "# This keeps all rows from 'df_merged' and the matched rows from 'master'\n",
        "master = master.merge(df_merged, on='row_id', how='right')\n",
        "\n",
        "# Rename the column 'target_x' to 'target' in the 'master' DataFrame\n",
        "master = master.rename(columns={'target_x': 'target'})\n",
        "\n",
        "# Drop the column 'target_y' from the 'master' DataFrame\n",
        "master = master.drop(['target_y'], axis=1)\n",
        "\n",
        "# Select and reorder specific columns in the 'master' DataFrame\n",
        "master = master[['row_id', 'order', 'target', 'realized_vol']]\n",
        "\n",
        "# Extract the stock identifier from 'row_id' and create a new column 'stock'\n",
        "master['stock'] = master['row_id'].str.split('-').str[0]\n",
        "\n",
        "# Finalize the DataFrame by selecting specific columns\n",
        "master = master[['stock', 'row_id', 'order', 'target', 'realized_vol']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_shifted_volatilities(df, n_before, n_after):\n",
        "    # Ensure the DataFrame is sorted by 'stock' and then by 'order'\n",
        "    df = df.sort_values(by=['stock', 'order'])\n",
        "    \n",
        "    # Generate shifted columns for prior volatilities\n",
        "    for i in range(1, n_before + 1):\n",
        "        shifted_col_name = f'previous_vol_{i}'\n",
        "        df[shifted_col_name] = df.groupby('stock')['realized_vol'].shift(i)\n",
        "        # Fill NaN values for the first 'n_before' rows within each stock group with the first available 'realized_vol' in that group\n",
        "        df[shifted_col_name] = df.groupby('stock')[shifted_col_name].transform(lambda x: x.fillna(method='bfill'))\n",
        "    \n",
        "    # Generate shifted columns for following volatilities\n",
        "    for i in range(1, n_after + 1):\n",
        "        shifted_col_name = f'next_vol_{i}'\n",
        "        df[shifted_col_name] = df.groupby('stock')['realized_vol'].shift(-i)\n",
        "        # Fill NaN values for the last 'n_after' rows within each stock group with the last available 'realized_vol' in that group\n",
        "        df[shifted_col_name] = df.groupby('stock')[shifted_col_name].transform(lambda x: x.fillna(method='ffill'))\n",
        "\n",
        "    return df\n",
        "\n",
        "n_before = 3  # Number of previous volatilities to include\n",
        "n_after = 3   # Number of following volatilities to include\n",
        "master = add_shifted_volatilities(master, n_before, n_after)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Aggregated Time Bucket Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "S9Sp2xdtxDu6"
      },
      "outputs": [],
      "source": [
        "def calculate_wap(df):\n",
        "    return ((df['bid_price1'] * df['ask_size1']) + (df['ask_price1'] * df['bid_size1'])) / (df['bid_size1'] + df['ask_size1'])\n",
        "\n",
        "def calculate_price_spread(df):\n",
        "    return (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
        "\n",
        "def calculate_bid_ask_spread(df, bid_col, ask_col):\n",
        "    return df[ask_col] - df[bid_col]\n",
        "\n",
        "def calculate_total_volume(df):\n",
        "    return df[['ask_size1', 'ask_size2', 'bid_size1', 'bid_size2']].sum(axis=1)\n",
        "\n",
        "def calculate_volume_imbalance(df):\n",
        "    return abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
        "\n",
        "def book_aggregate_features_per_time_id(file_path, feature_aggregations):\n",
        "    df_book_data = pd.read_parquet(file_path)\n",
        "    stock_id = int(file_path.split('=')[1])\n",
        "\n",
        "    # Precompute complex features\n",
        "    df_book_data['wap'] = calculate_wap(df_book_data)  \n",
        "    df_book_data['price_spread'] = calculate_price_spread(df_book_data)\n",
        "    df_book_data['bid_spread'] = calculate_bid_ask_spread(df_book_data, 'bid_price1', 'bid_price2')\n",
        "    df_book_data['ask_spread'] = calculate_bid_ask_spread(df_book_data, 'ask_price1', 'ask_price2')\n",
        "    df_book_data['total_volume'] = calculate_total_volume(df_book_data)\n",
        "    df_book_data['volume_imbalance'] = calculate_volume_imbalance(df_book_data)\n",
        "\n",
        "    # Prepare aggregation\n",
        "    aggregation_dict = {}\n",
        "    for new_name, (original, agg_func) in feature_aggregations.items():\n",
        "        aggregation_dict.setdefault(original, []).append((new_name, agg_func))\n",
        "\n",
        "    # Aggregate features\n",
        "    df_aggregated = df_book_data.groupby('time_id').agg(\n",
        "        {key: [func for _, func in value] for key, value in aggregation_dict.items()}\n",
        "    )\n",
        "\n",
        "    # Simplify MultiIndex in columns\n",
        "    df_aggregated.columns = [\n",
        "        f\"{original}_{agg_func.__name__ if callable(agg_func) else agg_func}\"\n",
        "        for original, funcs in aggregation_dict.items() for _, agg_func in funcs\n",
        "    ]\n",
        "\n",
        "    # Efficient row_id creation\n",
        "    df_aggregated['row_id'] = f\"{stock_id}-\" + df_aggregated.index.astype(str)\n",
        "    df_aggregated.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Reorder columns\n",
        "    cols = ['row_id'] + [col for col in df_aggregated.columns if col != 'row_id']\n",
        "    df_aggregated = df_aggregated[cols]\n",
        "\n",
        "    return df_aggregated\n",
        "\n",
        "def book_aggregate_features_for_all_stocks(list_file, feature_aggregations):\n",
        "    aggregated_data = [book_aggregate_features_per_time_id(file, feature_aggregations) for file in list_file]\n",
        "    return pd.concat(aggregated_data, ignore_index=True)\n",
        "\n",
        "def append_book_flattened_feature(list_file, flattened_feature, master):\n",
        "    df_aggregated_book = book_aggregate_features_for_all_stocks(list_file, flattened_feature)\n",
        "    master = pd.merge(master, df_aggregated_book, on='row_id', how='left')\n",
        "    return master\n",
        "\n",
        "def max_div_avg(series):\n",
        "    \"\"\"Returns the ratio of the maximum to the average of a series.\"\"\"\n",
        "    if series.mean() != 0:\n",
        "        return series.max() / series.mean()\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "def abs_price_change_first_last(series):\n",
        "    \"\"\"Returns the absolute difference between the first and last values of a series.\"\"\"\n",
        "    return abs(series.iloc[-1] - series.iloc[0])\n",
        "\n",
        "def price_spread(series_ask, series_bid):\n",
        "    \"\"\"Calculate price spread; requires preprocessing to apply.\"\"\"\n",
        "    return (series_ask - series_bid) / ((series_ask + series_bid) / 2)\n",
        "\n",
        "def bid_ask_spread(series_ask_price, series_bid_price):\n",
        "    \"\"\"Calculate bid and ask spread; requires preprocessing to apply.\"\"\"\n",
        "    return series_ask_price - series_bid_price\n",
        "\n",
        "def total_volume(series_ask_size, series_bid_size):\n",
        "    \"\"\"Calculate total volume; requires preprocessing to apply.\"\"\"\n",
        "    return series_ask_size.sum() + series_bid_size.sum()\n",
        "\n",
        "def volume_imbalance(series_ask_size, series_bid_size):\n",
        "    \"\"\"Calculate volume imbalance; requires preprocessing to apply.\"\"\"\n",
        "    return abs(series_ask_size.sum() - series_bid_size.sum())\n",
        "\n",
        "def calculate_wap(df):\n",
        "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
        "    return wap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "book_aggregations = {\n",
        "    'max_bid_size_div_avg_bid_size': ('bid_size1', max_div_avg),\n",
        "    'max_ask_size_div_avg_ask_size': ('ask_size1', max_div_avg),\n",
        "    'ask_price2_ptp': ('ask_price2', np.ptp),\n",
        "    'bid_price2_ptp': ('bid_price2', np.ptp),\n",
        "    'ask_price2_calculate_percent_change_from_extremes': ('ask_price2', calculate_percent_change_from_extremes),\n",
        "    'bid_price2_calculate_percent_change_froxm_extremes': ('bid_price2', calculate_percent_change_from_extremes),\n",
        "    'ask_price1_ptp': ('ask_price1', np.ptp),\n",
        "    'bid_price1_ptp': ('bid_price1', np.ptp),\n",
        "    'ask_price1_calculate_percent_change_from_extremes': ('ask_price1', calculate_percent_change_from_extremes),\n",
        "    'bid_price1_calculate_percent_change_from_extremes': ('bid_price1', calculate_percent_change_from_extremes),\n",
        "    'ask_price2_max': ('ask_price2', 'max'),\n",
        "    'ask_price1_max': ('ask_price1', 'max'),\n",
        "    'abs_bid_price_change': ('bid_price1', abs_price_change_first_last),\n",
        "    'abs_ask_price_change': ('ask_price1', abs_price_change_first_last),\n",
        "    'wap_mean': ('wap', 'mean'),\n",
        "    'price_spread_mean': ('price_spread', 'mean'),  # Assuming 'price_spread' is pre-calculated\n",
        "    'bid_spread_mean': ('bid_spread', 'mean'),  # Assuming 'bid_spread' is pre-calculated\n",
        "    'ask_spread_mean': ('ask_spread', 'mean'),  # Assuming 'ask_spread' is pre-calculated\n",
        "    'volume_imbalance_mean': ('volume_imbalance', 'mean'),\n",
        "    'total_volume_mean': ('total_volume', 'mean'),\n",
        "}\n",
        "\n",
        "master = append_book_flattened_feature(list_order_book_file_train, book_aggregations, master)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "WXyKWI2pxaOb"
      },
      "outputs": [],
      "source": [
        "def trade_aggregate_features_per_time_id(file_path, feature_aggregations):\n",
        "    df_trade_data = pd.read_parquet(file_path)\n",
        "    stock_id = int(file_path.split('=')[1])\n",
        "\n",
        "    # Prepare the aggregation dictionary\n",
        "    aggregation_dict = {}\n",
        "    for new_name, (original, agg_func) in feature_aggregations.items():\n",
        "        aggregation_dict.setdefault(original, []).append((new_name, agg_func))\n",
        "\n",
        "    # Aggregate features\n",
        "    df_aggregated = df_trade_data.groupby('time_id').agg(\n",
        "        {key: [func for _, func in value] for key, value in aggregation_dict.items()}\n",
        "    )\n",
        "\n",
        "    # Simplify MultiIndex in columns\n",
        "    df_aggregated.columns = [\n",
        "        f\"{original}_{agg_func.__name__ if callable(agg_func) else agg_func}\"\n",
        "        for original, funcs in aggregation_dict.items() for _, agg_func in funcs\n",
        "    ]\n",
        "\n",
        "    # Efficient row_id creation\n",
        "    df_aggregated['row_id'] = f\"{stock_id}-\" + df_aggregated.index.astype(str)\n",
        "    df_aggregated.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Reorder columns\n",
        "    cols = ['row_id'] + [col for col in df_aggregated.columns if col != 'row_id']\n",
        "    df_aggregated = df_aggregated[cols]\n",
        "\n",
        "    return df_aggregated\n",
        "\n",
        "def trade_aggregate_features_for_all_stocks(list_file, feature_aggregations):\n",
        "    aggregated_data = [trade_aggregate_features_per_time_id(file, feature_aggregations) for file in list_file]\n",
        "    return pd.concat(aggregated_data, ignore_index=True)\n",
        "\n",
        "def append_trade_flattened_feature(list_file, flattened_feature, master):\n",
        "    df_aggregated_trade = trade_aggregate_features_for_all_stocks(list_file, flattened_feature)\n",
        "    master = pd.merge(master, df_aggregated_trade, on='row_id', how='left')\n",
        "    return master\n",
        "\n",
        "def calculate_percent_change(series):\n",
        "    return (series.iloc[-1] - series.iloc[0]) / series.iloc[0] if series.iloc[0] != 0 else np.nan\n",
        "\n",
        "def calculate_percent_change_from_extremes(series):\n",
        "    return (series.max() - series.min()) / series.min() if series.min() != 0 else np.nan\n",
        "\n",
        "def abs_price_change(series):\n",
        "    \"\"\"Returns the absolute price change within the series.\"\"\"\n",
        "    return abs(series.iloc[-1] - series.iloc[0])\n",
        "\n",
        "def max_div_avg_size(series):\n",
        "    \"\"\"Returns the ratio of the max size to the average size.\"\"\"\n",
        "    if series.mean() != 0:\n",
        "        return series.max() / series.mean()\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "def max_div_avg_order_count(series):\n",
        "    \"\"\"Returns the ratio of the max order count to the average order count.\"\"\"\n",
        "    if series.mean() != 0:\n",
        "        return series.max() / series.mean()\n",
        "    else:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "trade_aggregations = {\n",
        "    'price_ptp': ('price', np.ptp),\n",
        "    'price_calculate_percent_change_from_extremes': ('price', calculate_percent_change_from_extremes),\n",
        "    'abs_price_last_first': ('price', abs_price_change),\n",
        "    'max_size_div_avg_size': ('size', max_div_avg_size),\n",
        "    'max_order_count_div_avg_order_count': ('order_count', max_div_avg_order_count),\n",
        "    'avg_size': ('size', 'mean'),\n",
        "    'avg_order_count': ('order_count', 'mean'),\n",
        "    'trade_seconds_in_bucket_count_unique': ('seconds_in_bucket', 'nunique'),\n",
        "    'trade_size_sum': ('size', 'sum'),\n",
        "    'trade_order_count_mean': ('order_count', 'mean'),\n",
        "    'price_ptp': ('price', np.ptp),\n",
        "    'price_calculate_percent_change_from_extremes': ('price', calculate_percent_change_from_extremes),\n",
        "}\n",
        "\n",
        "master = append_trade_flattened_feature(list_order_trade_file_train, trade_aggregations, master)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "master = master.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Neighboring Volatility Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'master' is your DataFrame\n",
        "\n",
        "# Step 1: Select features for KNN\n",
        "X = master.drop(['row_id', 'target', 'realized_vol'], axis=1)\n",
        "\n",
        "# Step 2: Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 3: Apply KNN to find the nearest 3 neighbors (excluding the row itself, so k=4)\n",
        "knn = NearestNeighbors(n_neighbors=4, algorithm='auto').fit(X_scaled)\n",
        "distances, indices = knn.kneighbors(X_scaled)\n",
        "\n",
        "# Step 4: Extract 'realized_vol' from the three nearest neighbors\n",
        "master.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Initialize columns for neighbor's realized_vol\n",
        "master['neighbor_vol_1'] = np.nan\n",
        "master['neighbor_vol_2'] = np.nan\n",
        "master['neighbor_vol_3'] = np.nan\n",
        "\n",
        "for i in range(len(indices)):\n",
        "    # Get the indices of the three nearest neighbors (excluding the row itself)\n",
        "    neighbors_indices = indices[i, 1:]  # Exclude the first index since it's the row itself\n",
        "    \n",
        "    # Use the DataFrame's index to correctly reference rows for 'realized_vol'\n",
        "    neighbor_vols = master.iloc[neighbors_indices]['realized_vol'].values\n",
        "    \n",
        "    # Assign 'realized_vol' values from neighbors\n",
        "    master.at[i, 'neighbor_vol_1'] = neighbor_vols[0]\n",
        "    master.at[i, 'neighbor_vol_2'] = neighbor_vols[1]\n",
        "    master.at[i, 'neighbor_vol_3'] = neighbor_vols[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pre-Model Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "neVlY6pD5Y8o"
      },
      "outputs": [],
      "source": [
        "master = master.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Positively Correlated Features with 'target':\n",
            "realized_vol                                         0.873782\n",
            "neighbor_vol_1                                       0.835055\n",
            "neighbor_vol_2                                       0.829721\n",
            "neighbor_vol_3                                       0.827051\n",
            "price_spread_mean                                    0.752907\n",
            "ask_price2_ptp                                       0.723822\n",
            "bid_price2_ptp                                       0.722555\n",
            "ask_price2_calculate_percent_change_from_extremes    0.721811\n",
            "bid_price2_calculate_percent_change_from_extremes    0.721391\n",
            "ask_price1_ptp                                       0.717661\n",
            "bid_price1_ptp                                       0.717583\n",
            "bid_price1_calculate_percent_change_from_extremes    0.716314\n",
            "ask_price1_calculate_percent_change_from_extremes    0.715730\n",
            "price_ptp                                            0.702566\n",
            "price_calculate_percent_change_from_extremes         0.700976\n",
            "next_vol_1                                           0.669144\n",
            "previous_vol_1                                       0.661723\n",
            "next_vol_2                                           0.619311\n",
            "previous_vol_2                                       0.615464\n",
            "next_vol_3                                           0.589560\n",
            "previous_vol_3                                       0.579519\n",
            "bid_price1_abs_price_change_first_last               0.532092\n",
            "ask_price1_abs_price_change_first_last               0.532028\n",
            "price_abs_price_change                               0.530796\n",
            "ask_price2_max                                       0.435032\n",
            "ask_spread_mean                                      0.428855\n",
            "ask_price1_max                                       0.411688\n",
            "bid_size1_max_div_avg                                0.151730\n",
            "ask_size1_max_div_avg                                0.132252\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_mean                                     0.087330\n",
            "order_count_max_div_avg_order_count                  0.069163\n",
            "size_max_div_avg_size                                0.067118\n",
            "seconds_in_bucket_nunique                            0.043729\n",
            "size_sum                                             0.036423\n",
            "wap_mean                                            -0.022303\n",
            "size_mean                                           -0.041525\n",
            "volume_imbalance_mean                               -0.048862\n",
            "total_volume_mean                                   -0.061919\n",
            "order                                               -0.109196\n",
            "bid_spread_mean                                     -0.419546\n",
            "dtype: float64\n",
            "\n",
            "Most Negatively Correlated Features with 'target':\n",
            "size_mean               -0.041525\n",
            "volume_imbalance_mean   -0.048862\n",
            "total_volume_mean       -0.061919\n",
            "order                   -0.109196\n",
            "bid_spread_mean         -0.419546\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Filter out non-numeric columns (excluding 'target' for correlation calculation)\n",
        "numeric_cols = master.select_dtypes(include=[np.number]).columns.tolist()\n",
        "numeric_cols.remove('target')  # Remove 'target' from the list to avoid self-correlation\n",
        "\n",
        "# Calculate correlations with the 'target' feature directly\n",
        "target_correlations = master[numeric_cols].apply(lambda x: x.corr(master['target']))\n",
        "\n",
        "# Sort the correlations\n",
        "sorted_correlations = target_correlations.sort_values(ascending=False)\n",
        "\n",
        "# Print most positively and negatively correlated features\n",
        "print(\"Most Positively Correlated Features with 'target':\")\n",
        "print(sorted_correlations)  # Adjust the number as needed\n",
        "\n",
        "print(\"\\nMost Negatively Correlated Features with 'target':\")\n",
        "print(sorted_correlations.tail())  # Adjust the number as needed\n",
        "\n",
        "# Convert the sorted correlations series to a DataFrame\n",
        "sorted_correlations_df = sorted_correlations.reset_index()\n",
        "sorted_correlations_df.columns = ['Feature', 'Correlation_with_Target']\n",
        "\n",
        "# Filter for features with a correlation greater than 0.2\n",
        "high_correlation_features = sorted_correlations_df[sorted_correlations_df['Correlation_with_Target'] > 0]['Feature']\n",
        "\n",
        "# Select the filtered features from the master DataFrame\n",
        "filtered_master = master[['row_id', 'target'] + high_correlation_features.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>target</th>\n",
              "      <th>realized_vol</th>\n",
              "      <th>neighbor_vol_1</th>\n",
              "      <th>neighbor_vol_2</th>\n",
              "      <th>neighbor_vol_3</th>\n",
              "      <th>price_spread_mean</th>\n",
              "      <th>ask_price2_ptp</th>\n",
              "      <th>bid_price2_ptp</th>\n",
              "      <th>ask_price2_calculate_percent_change_from_extremes</th>\n",
              "      <th>bid_price2_calculate_percent_change_from_extremes</th>\n",
              "      <th>ask_price1_ptp</th>\n",
              "      <th>bid_price1_ptp</th>\n",
              "      <th>bid_price1_calculate_percent_change_from_extremes</th>\n",
              "      <th>ask_price1_calculate_percent_change_from_extremes</th>\n",
              "      <th>price_ptp</th>\n",
              "      <th>price_calculate_percent_change_from_extremes</th>\n",
              "      <th>next_vol_1</th>\n",
              "      <th>previous_vol_1</th>\n",
              "      <th>next_vol_2</th>\n",
              "      <th>previous_vol_2</th>\n",
              "      <th>next_vol_3</th>\n",
              "      <th>previous_vol_3</th>\n",
              "      <th>bid_price1_abs_price_change_first_last</th>\n",
              "      <th>ask_price1_abs_price_change_first_last</th>\n",
              "      <th>price_abs_price_change</th>\n",
              "      <th>ask_price2_max</th>\n",
              "      <th>ask_spread_mean</th>\n",
              "      <th>ask_price1_max</th>\n",
              "      <th>bid_size1_max_div_avg</th>\n",
              "      <th>ask_size1_max_div_avg</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_max_div_avg_order_count</th>\n",
              "      <th>size_max_div_avg_size</th>\n",
              "      <th>seconds_in_bucket_nunique</th>\n",
              "      <th>size_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0-4294</td>\n",
              "      <td>0.003267</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.006266</td>\n",
              "      <td>0.005423</td>\n",
              "      <td>0.003780</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>0.009381</td>\n",
              "      <td>0.003181</td>\n",
              "      <td>0.009408</td>\n",
              "      <td>0.003505</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.004682</td>\n",
              "      <td>0.003490</td>\n",
              "      <td>0.003957</td>\n",
              "      <td>0.003943</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>0.001598</td>\n",
              "      <td>0.001756</td>\n",
              "      <td>1.007990</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>1.007732</td>\n",
              "      <td>2.806304</td>\n",
              "      <td>6.434691</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.498525</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0-24033</td>\n",
              "      <td>0.002580</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.004334</td>\n",
              "      <td>0.003503</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.002452</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.002458</td>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.002503</td>\n",
              "      <td>0.002810</td>\n",
              "      <td>0.002820</td>\n",
              "      <td>0.002510</td>\n",
              "      <td>0.001908</td>\n",
              "      <td>0.001913</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.002299</td>\n",
              "      <td>0.002197</td>\n",
              "      <td>0.001890</td>\n",
              "      <td>1.000128</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.999923</td>\n",
              "      <td>2.440895</td>\n",
              "      <td>3.456275</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>2.212766</td>\n",
              "      <td>3.214815</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1755.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0-5666</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.003481</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.002048</td>\n",
              "      <td>0.001333</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002048</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>0.001078</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.000717</td>\n",
              "      <td>0.001024</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.999898</td>\n",
              "      <td>3.053678</td>\n",
              "      <td>4.802214</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>4.578947</td>\n",
              "      <td>4.770754</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1313.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0-29740</td>\n",
              "      <td>0.002364</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.003481</td>\n",
              "      <td>0.003590</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.001692</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>1.001563</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>1.001461</td>\n",
              "      <td>2.944738</td>\n",
              "      <td>4.280906</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>3.319149</td>\n",
              "      <td>4.967666</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1701.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0-22178</td>\n",
              "      <td>0.001439</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.001628</td>\n",
              "      <td>0.002264</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.002514</td>\n",
              "      <td>0.002719</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.002616</td>\n",
              "      <td>0.002719</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.002623</td>\n",
              "      <td>0.002411</td>\n",
              "      <td>0.002417</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001949</td>\n",
              "      <td>1.000205</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>1.000051</td>\n",
              "      <td>3.586559</td>\n",
              "      <td>3.590304</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>5.150943</td>\n",
              "      <td>7.735746</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2017.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428908</th>\n",
              "      <td>99-24913</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>0.001274</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001394</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.000982</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.000831</td>\n",
              "      <td>2.247635</td>\n",
              "      <td>2.343238</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.613497</td>\n",
              "      <td>7.736945</td>\n",
              "      <td>61.0</td>\n",
              "      <td>21524.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428909</th>\n",
              "      <td>99-32195</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.001509</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.001664</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.000906</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>1.000226</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.000075</td>\n",
              "      <td>3.261741</td>\n",
              "      <td>6.643945</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>11.666667</td>\n",
              "      <td>14.251719</td>\n",
              "      <td>100.0</td>\n",
              "      <td>26474.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428910</th>\n",
              "      <td>99-15365</td>\n",
              "      <td>0.001257</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.001595</td>\n",
              "      <td>0.001367</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002264</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.002264</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.002113</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>1.001584</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.001433</td>\n",
              "      <td>3.384056</td>\n",
              "      <td>10.750909</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>4.155738</td>\n",
              "      <td>3.794150</td>\n",
              "      <td>78.0</td>\n",
              "      <td>16138.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428911</th>\n",
              "      <td>99-10890</td>\n",
              "      <td>0.002815</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001466</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>0.001246</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>0.002112</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>1.000678</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.000527</td>\n",
              "      <td>3.441576</td>\n",
              "      <td>3.883602</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>5.197452</td>\n",
              "      <td>6.327757</td>\n",
              "      <td>96.0</td>\n",
              "      <td>51825.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428912</th>\n",
              "      <td>99-29316</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001784</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.001367</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001960</td>\n",
              "      <td>0.001811</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.002338</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>1.002187</td>\n",
              "      <td>3.974785</td>\n",
              "      <td>5.009612</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>5.003344</td>\n",
              "      <td>6.472060</td>\n",
              "      <td>68.0</td>\n",
              "      <td>20383.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>428913 rows  99 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          row_id    target  realized_vol  neighbor_vol_1  neighbor_vol_2  \\\n",
              "0         0-4294  0.003267      0.007026        0.006266        0.005423   \n",
              "1        0-24033  0.002580      0.004136        0.002395        0.004334   \n",
              "2         0-5666  0.002051      0.002395        0.003481        0.003443   \n",
              "3        0-29740  0.002364      0.001790        0.001958        0.003481   \n",
              "4        0-22178  0.001439      0.002601        0.001628        0.002264   \n",
              "...          ...       ...           ...             ...             ...   \n",
              "428908  99-24913  0.001040      0.001153        0.001007        0.000905   \n",
              "428909  99-32195  0.001248      0.001502        0.001670        0.001790   \n",
              "428910  99-15365  0.001257      0.001379        0.001569        0.001595   \n",
              "428911  99-10890  0.002815      0.001468        0.001466        0.001355   \n",
              "428912  99-29316  0.001351      0.001443        0.001784        0.001616   \n",
              "\n",
              "        neighbor_vol_3  price_spread_mean  ask_price2_ptp  bid_price2_ptp  \\\n",
              "0             0.003780           0.002081        0.003196        0.009381   \n",
              "1             0.003503           0.000786        0.002452        0.002759   \n",
              "2             0.001790           0.000456        0.001332        0.002048   \n",
              "3             0.003590           0.000576        0.001384        0.001692   \n",
              "4             0.001196           0.000617        0.002514        0.002719   \n",
              "...                ...                ...             ...             ...   \n",
              "428908        0.001274           0.000158        0.001208        0.001208   \n",
              "428909        0.001905           0.000164        0.001509        0.001661   \n",
              "428910        0.001367           0.000172        0.002262        0.002262   \n",
              "428911        0.001246           0.000154        0.002259        0.002259   \n",
              "428912        0.001367           0.000181        0.001961        0.001810   \n",
              "\n",
              "        ask_price2_calculate_percent_change_from_extremes  \\\n",
              "0                                                0.003181   \n",
              "1                                                0.002458   \n",
              "2                                                0.001333   \n",
              "3                                                0.001384   \n",
              "4                                                0.002519   \n",
              "...                                                   ...   \n",
              "428908                                           0.001209   \n",
              "428909                                           0.001511   \n",
              "428910                                           0.002264   \n",
              "428911                                           0.002262   \n",
              "428912                                           0.001960   \n",
              "\n",
              "        bid_price2_calculate_percent_change_from_extremes  ask_price1_ptp  \\\n",
              "0                                                0.009408        0.003505   \n",
              "1                                                0.002768        0.002503   \n",
              "2                                                0.002054        0.001280   \n",
              "3                                                0.001693        0.001486   \n",
              "4                                                0.002728        0.002616   \n",
              "...                                                   ...             ...   \n",
              "428908                                           0.001209        0.001208   \n",
              "428909                                           0.001664        0.001510   \n",
              "428910                                           0.002265        0.002262   \n",
              "428911                                           0.002263        0.002259   \n",
              "428912                                           0.001811        0.001961   \n",
              "\n",
              "        bid_price1_ptp  bid_price1_calculate_percent_change_from_extremes  \\\n",
              "0             0.004691                                           0.004682   \n",
              "1             0.002810                                           0.002820   \n",
              "2             0.002048                                           0.002054   \n",
              "3             0.001281                                           0.001282   \n",
              "4             0.002719                                           0.002728   \n",
              "...                ...                                                ...   \n",
              "428908        0.001208                                           0.001209   \n",
              "428909        0.001661                                           0.001663   \n",
              "428910        0.002262                                           0.002265   \n",
              "428911        0.002259                                           0.002263   \n",
              "428912        0.001810                                           0.001810   \n",
              "\n",
              "        ask_price1_calculate_percent_change_from_extremes  price_ptp  \\\n",
              "0                                                0.003490   0.003957   \n",
              "1                                                0.002510   0.001908   \n",
              "2                                                0.001282   0.001078   \n",
              "3                                                0.001486   0.001076   \n",
              "4                                                0.002623   0.002411   \n",
              "...                                                   ...        ...   \n",
              "428908                                           0.001209   0.001195   \n",
              "428909                                           0.001512   0.001510   \n",
              "428910                                           0.002264   0.002111   \n",
              "428911                                           0.002262   0.002108   \n",
              "428912                                           0.001961   0.001810   \n",
              "\n",
              "        price_calculate_percent_change_from_extremes  next_vol_1  \\\n",
              "0                                           0.003943    0.004136   \n",
              "1                                           0.001913    0.002395   \n",
              "2                                           0.001080    0.001790   \n",
              "3                                           0.001076    0.002601   \n",
              "4                                           0.002417    0.001465   \n",
              "...                                              ...         ...   \n",
              "428908                                      0.001196    0.001502   \n",
              "428909                                      0.001512    0.001379   \n",
              "428910                                      0.002113    0.001468   \n",
              "428911                                      0.002112    0.001443   \n",
              "428912                                      0.001810    0.001443   \n",
              "\n",
              "        previous_vol_1  next_vol_2  previous_vol_2  next_vol_3  \\\n",
              "0             0.007026    0.002395        0.007026    0.001790   \n",
              "1             0.007026    0.001790        0.007026    0.002601   \n",
              "2             0.004136    0.002601        0.007026    0.001465   \n",
              "3             0.002395    0.001465        0.004136    0.001474   \n",
              "4             0.001790    0.001474        0.002395    0.000891   \n",
              "...                ...         ...             ...         ...   \n",
              "428908        0.001301    0.001379        0.001368    0.001468   \n",
              "428909        0.001153    0.001468        0.001301    0.001443   \n",
              "428910        0.001502    0.001443        0.001153    0.001443   \n",
              "428911        0.001379    0.001443        0.001502    0.001443   \n",
              "428912        0.001468    0.001443        0.001379    0.001443   \n",
              "\n",
              "        previous_vol_3  bid_price1_abs_price_change_first_last  \\\n",
              "0             0.007026                                0.003608   \n",
              "1             0.007026                                0.002299   \n",
              "2             0.007026                                0.000717   \n",
              "3             0.007026                                0.000308   \n",
              "4             0.004136                                0.001642   \n",
              "...                ...                                     ...   \n",
              "428908        0.001394                                0.000302   \n",
              "428909        0.001368                                0.000906   \n",
              "428910        0.001301                                0.001056   \n",
              "428911        0.001153                                0.000301   \n",
              "428912        0.001502                                0.000302   \n",
              "\n",
              "        ask_price1_abs_price_change_first_last  price_abs_price_change  \\\n",
              "0                                     0.001598                0.001756   \n",
              "1                                     0.002197                0.001890   \n",
              "2                                     0.001024                0.000559   \n",
              "3                                     0.000410                0.000308   \n",
              "4                                     0.001744                0.001949   \n",
              "...                                        ...                     ...   \n",
              "428908                                0.000302                0.000151   \n",
              "428909                                0.000755                0.000604   \n",
              "428910                                0.001056                0.001056   \n",
              "428911                                0.000301                0.000455   \n",
              "428912                                0.000151                0.000151   \n",
              "\n",
              "        ask_price2_max  ask_spread_mean  ask_price1_max  \\\n",
              "0             1.007990         0.000423        1.007732   \n",
              "1             1.000128         0.000199        0.999923   \n",
              "2             1.000000         0.000176        0.999898   \n",
              "3             1.001563         0.000185        1.001461   \n",
              "4             1.000205         0.000165        1.000051   \n",
              "...                ...              ...             ...   \n",
              "428908        1.000982         0.000151        1.000831   \n",
              "428909        1.000226         0.000151        1.000075   \n",
              "428910        1.001584         0.000151        1.001433   \n",
              "428911        1.000678         0.000151        1.000527   \n",
              "428912        1.002338         0.000151        1.002187   \n",
              "\n",
              "        bid_size1_max_div_avg  ask_size1_max_div_avg  order_count_mean  \\\n",
              "0                    2.806304               6.434691          3.857143   \n",
              "1                    2.440895               3.456275          1.807692   \n",
              "2                    3.053678               4.802214          1.965517   \n",
              "3                    2.944738               4.280906          1.807692   \n",
              "4                    3.586559               3.590304          2.523810   \n",
              "...                       ...                    ...               ...   \n",
              "428908               2.247635               2.343238          5.344262   \n",
              "428909               3.261741               6.643945          3.600000   \n",
              "428910               3.384056              10.750909          3.128205   \n",
              "428911               3.441576               3.883602          6.541667   \n",
              "428912               3.974785               5.009612          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        order_count_max_div_avg_order_count  size_max_div_avg_size  \\\n",
              "0                                  2.333333               2.498525   \n",
              "1                                  2.212766               3.214815   \n",
              "2                                  4.578947               4.770754   \n",
              "3                                  3.319149               4.967666   \n",
              "4                                  5.150943               7.735746   \n",
              "...                                     ...                    ...   \n",
              "428908                             5.613497               7.736945   \n",
              "428909                            11.666667              14.251719   \n",
              "428910                             4.155738               3.794150   \n",
              "428911                             5.197452               6.327757   \n",
              "428912                             5.003344               6.472060   \n",
              "\n",
              "        seconds_in_bucket_nunique  size_sum  \n",
              "0                            14.0    2034.0  \n",
              "1                            26.0    1755.0  \n",
              "2                            29.0    1313.0  \n",
              "3                            26.0    1701.0  \n",
              "4                            21.0    2017.0  \n",
              "...                           ...       ...  \n",
              "428908                       61.0   21524.0  \n",
              "428909                      100.0   26474.0  \n",
              "428910                       78.0   16138.0  \n",
              "428911                       96.0   51825.0  \n",
              "428912                       68.0   20383.0  \n",
              "\n",
              "[428913 rows x 99 columns]"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>row_id</th>\n",
              "      <th>order</th>\n",
              "      <th>target</th>\n",
              "      <th>realized_vol</th>\n",
              "      <th>previous_vol_1</th>\n",
              "      <th>previous_vol_2</th>\n",
              "      <th>previous_vol_3</th>\n",
              "      <th>next_vol_1</th>\n",
              "      <th>next_vol_2</th>\n",
              "      <th>next_vol_3</th>\n",
              "      <th>price_ptp</th>\n",
              "      <th>price_calculate_percent_change_from_extremes</th>\n",
              "      <th>price_abs_price_change</th>\n",
              "      <th>size_max_div_avg_size</th>\n",
              "      <th>size_mean</th>\n",
              "      <th>size_sum</th>\n",
              "      <th>order_count_max_div_avg_order_count</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>order_count_mean</th>\n",
              "      <th>seconds_in_bucket_nunique</th>\n",
              "      <th>bid_size1_max_div_avg</th>\n",
              "      <th>ask_size1_max_div_avg</th>\n",
              "      <th>ask_price2_ptp</th>\n",
              "      <th>ask_price2_calculate_percent_change_from_extremes</th>\n",
              "      <th>ask_price2_max</th>\n",
              "      <th>bid_price2_ptp</th>\n",
              "      <th>bid_price2_calculate_percent_change_from_extremes</th>\n",
              "      <th>ask_price1_ptp</th>\n",
              "      <th>ask_price1_calculate_percent_change_from_extremes</th>\n",
              "      <th>ask_price1_max</th>\n",
              "      <th>ask_price1_abs_price_change_first_last</th>\n",
              "      <th>bid_price1_ptp</th>\n",
              "      <th>bid_price1_calculate_percent_change_from_extremes</th>\n",
              "      <th>bid_price1_abs_price_change_first_last</th>\n",
              "      <th>wap_mean</th>\n",
              "      <th>price_spread_mean</th>\n",
              "      <th>bid_spread_mean</th>\n",
              "      <th>ask_spread_mean</th>\n",
              "      <th>volume_imbalance_mean</th>\n",
              "      <th>total_volume_mean</th>\n",
              "      <th>neighbor_vol_1</th>\n",
              "      <th>neighbor_vol_2</th>\n",
              "      <th>neighbor_vol_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0-4294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003267</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.003957</td>\n",
              "      <td>0.003943</td>\n",
              "      <td>0.001756</td>\n",
              "      <td>2.498525</td>\n",
              "      <td>145.285714</td>\n",
              "      <td>2034.0</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.806304</td>\n",
              "      <td>6.434691</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>0.003181</td>\n",
              "      <td>1.007990</td>\n",
              "      <td>0.009381</td>\n",
              "      <td>0.009408</td>\n",
              "      <td>0.003505</td>\n",
              "      <td>0.003490</td>\n",
              "      <td>1.007732</td>\n",
              "      <td>0.001598</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.004682</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>1.005457</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>205.157609</td>\n",
              "      <td>498.081522</td>\n",
              "      <td>0.006266</td>\n",
              "      <td>0.005423</td>\n",
              "      <td>0.003780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0-24033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002580</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.001908</td>\n",
              "      <td>0.001913</td>\n",
              "      <td>0.001890</td>\n",
              "      <td>3.214815</td>\n",
              "      <td>67.500000</td>\n",
              "      <td>1755.0</td>\n",
              "      <td>2.212766</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.440895</td>\n",
              "      <td>3.456275</td>\n",
              "      <td>0.002452</td>\n",
              "      <td>0.002458</td>\n",
              "      <td>1.000128</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.002503</td>\n",
              "      <td>0.002510</td>\n",
              "      <td>0.999923</td>\n",
              "      <td>0.002197</td>\n",
              "      <td>0.002810</td>\n",
              "      <td>0.002820</td>\n",
              "      <td>0.002299</td>\n",
              "      <td>0.998583</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>-0.000088</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>116.313783</td>\n",
              "      <td>382.923754</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.004334</td>\n",
              "      <td>0.003503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0-5666</td>\n",
              "      <td>2</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001078</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>4.770754</td>\n",
              "      <td>45.275862</td>\n",
              "      <td>1313.0</td>\n",
              "      <td>4.578947</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>1.965517</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.053678</td>\n",
              "      <td>4.802214</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.001333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002048</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>0.999898</td>\n",
              "      <td>0.001024</td>\n",
              "      <td>0.002048</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.000717</td>\n",
              "      <td>0.998998</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>-0.000095</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>115.274576</td>\n",
              "      <td>319.016949</td>\n",
              "      <td>0.003481</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.001790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0-29740</td>\n",
              "      <td>3</td>\n",
              "      <td>0.002364</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>4.967666</td>\n",
              "      <td>65.423077</td>\n",
              "      <td>1701.0</td>\n",
              "      <td>3.319149</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>1.807692</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.944738</td>\n",
              "      <td>4.280906</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>1.001563</td>\n",
              "      <td>0.001692</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>1.001461</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>1.000602</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>-0.000101</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>174.898058</td>\n",
              "      <td>496.927184</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.003481</td>\n",
              "      <td>0.003590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0-22178</td>\n",
              "      <td>4</td>\n",
              "      <td>0.001439</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.002411</td>\n",
              "      <td>0.002417</td>\n",
              "      <td>0.001949</td>\n",
              "      <td>7.735746</td>\n",
              "      <td>96.047619</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>5.150943</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>2.523810</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.586559</td>\n",
              "      <td>3.590304</td>\n",
              "      <td>0.002514</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>1.000205</td>\n",
              "      <td>0.002719</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.002616</td>\n",
              "      <td>0.002623</td>\n",
              "      <td>1.000051</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.002719</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.998349</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>-0.000087</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>148.091667</td>\n",
              "      <td>482.441667</td>\n",
              "      <td>0.001628</td>\n",
              "      <td>0.002264</td>\n",
              "      <td>0.001196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428908</th>\n",
              "      <td>99</td>\n",
              "      <td>99-24913</td>\n",
              "      <td>3825</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.001394</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>7.736945</td>\n",
              "      <td>352.852459</td>\n",
              "      <td>21524.0</td>\n",
              "      <td>5.613497</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>5.344262</td>\n",
              "      <td>61.0</td>\n",
              "      <td>2.247635</td>\n",
              "      <td>2.343238</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>1.000982</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>1.000831</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>1.000192</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>-0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>357.053830</td>\n",
              "      <td>2268.246377</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>0.001274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428909</th>\n",
              "      <td>99</td>\n",
              "      <td>99-32195</td>\n",
              "      <td>3826</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>14.251719</td>\n",
              "      <td>264.740000</td>\n",
              "      <td>26474.0</td>\n",
              "      <td>11.666667</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.261741</td>\n",
              "      <td>6.643945</td>\n",
              "      <td>0.001509</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>1.000226</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.001664</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>1.000075</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.000906</td>\n",
              "      <td>0.999309</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>-0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>631.287109</td>\n",
              "      <td>2172.791016</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.001905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428910</th>\n",
              "      <td>99</td>\n",
              "      <td>99-15365</td>\n",
              "      <td>3827</td>\n",
              "      <td>0.001257</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.002113</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>3.794150</td>\n",
              "      <td>206.897436</td>\n",
              "      <td>16138.0</td>\n",
              "      <td>4.155738</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>3.128205</td>\n",
              "      <td>78.0</td>\n",
              "      <td>3.384056</td>\n",
              "      <td>10.750909</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002264</td>\n",
              "      <td>1.001584</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002264</td>\n",
              "      <td>1.001433</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>1.000229</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>-0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>386.595238</td>\n",
              "      <td>1867.503968</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.001595</td>\n",
              "      <td>0.001367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428911</th>\n",
              "      <td>99</td>\n",
              "      <td>99-10890</td>\n",
              "      <td>3828</td>\n",
              "      <td>0.002815</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>0.002112</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>6.327757</td>\n",
              "      <td>539.843750</td>\n",
              "      <td>51825.0</td>\n",
              "      <td>5.197452</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>6.541667</td>\n",
              "      <td>96.0</td>\n",
              "      <td>3.441576</td>\n",
              "      <td>3.883602</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>1.000678</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002262</td>\n",
              "      <td>1.000527</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.999461</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>-0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>994.640777</td>\n",
              "      <td>3326.633010</td>\n",
              "      <td>0.001466</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>0.001246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428912</th>\n",
              "      <td>99</td>\n",
              "      <td>99-29316</td>\n",
              "      <td>3829</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>6.472060</td>\n",
              "      <td>299.750000</td>\n",
              "      <td>20383.0</td>\n",
              "      <td>5.003344</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>4.397059</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3.974785</td>\n",
              "      <td>5.009612</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001960</td>\n",
              "      <td>1.002338</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001811</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>1.002187</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>1.001094</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>-0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>445.455969</td>\n",
              "      <td>2089.162427</td>\n",
              "      <td>0.001784</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.001367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>428913 rows  46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       stock    row_id  order    target  realized_vol  previous_vol_1  \\\n",
              "0          0    0-4294      0  0.003267      0.007026        0.007026   \n",
              "1          0   0-24033      1  0.002580      0.004136        0.007026   \n",
              "2          0    0-5666      2  0.002051      0.002395        0.004136   \n",
              "3          0   0-29740      3  0.002364      0.001790        0.002395   \n",
              "4          0   0-22178      4  0.001439      0.002601        0.001790   \n",
              "...      ...       ...    ...       ...           ...             ...   \n",
              "428908    99  99-24913   3825  0.001040      0.001153        0.001301   \n",
              "428909    99  99-32195   3826  0.001248      0.001502        0.001153   \n",
              "428910    99  99-15365   3827  0.001257      0.001379        0.001502   \n",
              "428911    99  99-10890   3828  0.002815      0.001468        0.001379   \n",
              "428912    99  99-29316   3829  0.001351      0.001443        0.001468   \n",
              "\n",
              "        previous_vol_2  previous_vol_3  next_vol_1  next_vol_2  next_vol_3  \\\n",
              "0             0.007026        0.007026    0.004136    0.002395    0.001790   \n",
              "1             0.007026        0.007026    0.002395    0.001790    0.002601   \n",
              "2             0.007026        0.007026    0.001790    0.002601    0.001465   \n",
              "3             0.004136        0.007026    0.002601    0.001465    0.001474   \n",
              "4             0.002395        0.004136    0.001465    0.001474    0.000891   \n",
              "...                ...             ...         ...         ...         ...   \n",
              "428908        0.001368        0.001394    0.001502    0.001379    0.001468   \n",
              "428909        0.001301        0.001368    0.001379    0.001468    0.001443   \n",
              "428910        0.001153        0.001301    0.001468    0.001443    0.001443   \n",
              "428911        0.001502        0.001153    0.001443    0.001443    0.001443   \n",
              "428912        0.001379        0.001502    0.001443    0.001443    0.001443   \n",
              "\n",
              "        price_ptp  price_calculate_percent_change_from_extremes  \\\n",
              "0        0.003957                                      0.003943   \n",
              "1        0.001908                                      0.001913   \n",
              "2        0.001078                                      0.001080   \n",
              "3        0.001076                                      0.001076   \n",
              "4        0.002411                                      0.002417   \n",
              "...           ...                                           ...   \n",
              "428908   0.001195                                      0.001196   \n",
              "428909   0.001510                                      0.001512   \n",
              "428910   0.002111                                      0.002113   \n",
              "428911   0.002108                                      0.002112   \n",
              "428912   0.001810                                      0.001810   \n",
              "\n",
              "        price_abs_price_change  size_max_div_avg_size   size_mean  size_sum  \\\n",
              "0                     0.001756               2.498525  145.285714    2034.0   \n",
              "1                     0.001890               3.214815   67.500000    1755.0   \n",
              "2                     0.000559               4.770754   45.275862    1313.0   \n",
              "3                     0.000308               4.967666   65.423077    1701.0   \n",
              "4                     0.001949               7.735746   96.047619    2017.0   \n",
              "...                        ...                    ...         ...       ...   \n",
              "428908                0.000151               7.736945  352.852459   21524.0   \n",
              "428909                0.000604              14.251719  264.740000   26474.0   \n",
              "428910                0.001056               3.794150  206.897436   16138.0   \n",
              "428911                0.000455               6.327757  539.843750   51825.0   \n",
              "428912                0.000151               6.472060  299.750000   20383.0   \n",
              "\n",
              "        order_count_max_div_avg_order_count  order_count_mean  \\\n",
              "0                                  2.333333          3.857143   \n",
              "1                                  2.212766          1.807692   \n",
              "2                                  4.578947          1.965517   \n",
              "3                                  3.319149          1.807692   \n",
              "4                                  5.150943          2.523810   \n",
              "...                                     ...               ...   \n",
              "428908                             5.613497          5.344262   \n",
              "428909                            11.666667          3.600000   \n",
              "428910                             4.155738          3.128205   \n",
              "428911                             5.197452          6.541667   \n",
              "428912                             5.003344          4.397059   \n",
              "\n",
              "        order_count_mean  order_count_mean  order_count_mean  \\\n",
              "0               3.857143          3.857143          3.857143   \n",
              "1               1.807692          1.807692          1.807692   \n",
              "2               1.965517          1.965517          1.965517   \n",
              "3               1.807692          1.807692          1.807692   \n",
              "4               2.523810          2.523810          2.523810   \n",
              "...                  ...               ...               ...   \n",
              "428908          5.344262          5.344262          5.344262   \n",
              "428909          3.600000          3.600000          3.600000   \n",
              "428910          3.128205          3.128205          3.128205   \n",
              "428911          6.541667          6.541667          6.541667   \n",
              "428912          4.397059          4.397059          4.397059   \n",
              "\n",
              "        seconds_in_bucket_nunique  bid_size1_max_div_avg  \\\n",
              "0                            14.0               2.806304   \n",
              "1                            26.0               2.440895   \n",
              "2                            29.0               3.053678   \n",
              "3                            26.0               2.944738   \n",
              "4                            21.0               3.586559   \n",
              "...                           ...                    ...   \n",
              "428908                       61.0               2.247635   \n",
              "428909                      100.0               3.261741   \n",
              "428910                       78.0               3.384056   \n",
              "428911                       96.0               3.441576   \n",
              "428912                       68.0               3.974785   \n",
              "\n",
              "        ask_size1_max_div_avg  ask_price2_ptp  \\\n",
              "0                    6.434691        0.003196   \n",
              "1                    3.456275        0.002452   \n",
              "2                    4.802214        0.001332   \n",
              "3                    4.280906        0.001384   \n",
              "4                    3.590304        0.002514   \n",
              "...                       ...             ...   \n",
              "428908               2.343238        0.001208   \n",
              "428909               6.643945        0.001509   \n",
              "428910              10.750909        0.002262   \n",
              "428911               3.883602        0.002259   \n",
              "428912               5.009612        0.001961   \n",
              "\n",
              "        ask_price2_calculate_percent_change_from_extremes  ask_price2_max  \\\n",
              "0                                                0.003181        1.007990   \n",
              "1                                                0.002458        1.000128   \n",
              "2                                                0.001333        1.000000   \n",
              "3                                                0.001384        1.001563   \n",
              "4                                                0.002519        1.000205   \n",
              "...                                                   ...             ...   \n",
              "428908                                           0.001209        1.000982   \n",
              "428909                                           0.001511        1.000226   \n",
              "428910                                           0.002264        1.001584   \n",
              "428911                                           0.002262        1.000678   \n",
              "428912                                           0.001960        1.002338   \n",
              "\n",
              "        bid_price2_ptp  bid_price2_calculate_percent_change_from_extremes  \\\n",
              "0             0.009381                                           0.009408   \n",
              "1             0.002759                                           0.002768   \n",
              "2             0.002048                                           0.002054   \n",
              "3             0.001692                                           0.001693   \n",
              "4             0.002719                                           0.002728   \n",
              "...                ...                                                ...   \n",
              "428908        0.001208                                           0.001209   \n",
              "428909        0.001661                                           0.001664   \n",
              "428910        0.002262                                           0.002265   \n",
              "428911        0.002259                                           0.002263   \n",
              "428912        0.001810                                           0.001811   \n",
              "\n",
              "        ask_price1_ptp  ask_price1_calculate_percent_change_from_extremes  \\\n",
              "0             0.003505                                           0.003490   \n",
              "1             0.002503                                           0.002510   \n",
              "2             0.001280                                           0.001282   \n",
              "3             0.001486                                           0.001486   \n",
              "4             0.002616                                           0.002623   \n",
              "...                ...                                                ...   \n",
              "428908        0.001208                                           0.001209   \n",
              "428909        0.001510                                           0.001512   \n",
              "428910        0.002262                                           0.002264   \n",
              "428911        0.002259                                           0.002262   \n",
              "428912        0.001961                                           0.001961   \n",
              "\n",
              "        ask_price1_max  ask_price1_abs_price_change_first_last  \\\n",
              "0             1.007732                                0.001598   \n",
              "1             0.999923                                0.002197   \n",
              "2             0.999898                                0.001024   \n",
              "3             1.001461                                0.000410   \n",
              "4             1.000051                                0.001744   \n",
              "...                ...                                     ...   \n",
              "428908        1.000831                                0.000302   \n",
              "428909        1.000075                                0.000755   \n",
              "428910        1.001433                                0.001056   \n",
              "428911        1.000527                                0.000301   \n",
              "428912        1.002187                                0.000151   \n",
              "\n",
              "        bid_price1_ptp  bid_price1_calculate_percent_change_from_extremes  \\\n",
              "0             0.004691                                           0.004682   \n",
              "1             0.002810                                           0.002820   \n",
              "2             0.002048                                           0.002054   \n",
              "3             0.001281                                           0.001282   \n",
              "4             0.002719                                           0.002728   \n",
              "...                ...                                                ...   \n",
              "428908        0.001208                                           0.001209   \n",
              "428909        0.001661                                           0.001663   \n",
              "428910        0.002262                                           0.002265   \n",
              "428911        0.002259                                           0.002263   \n",
              "428912        0.001810                                           0.001810   \n",
              "\n",
              "        bid_price1_abs_price_change_first_last  wap_mean  price_spread_mean  \\\n",
              "0                                     0.003608  1.005457           0.002081   \n",
              "1                                     0.002299  0.998583           0.000786   \n",
              "2                                     0.000717  0.998998           0.000456   \n",
              "3                                     0.000308  1.000602           0.000576   \n",
              "4                                     0.001642  0.998349           0.000617   \n",
              "...                                        ...       ...                ...   \n",
              "428908                                0.000302  1.000192           0.000158   \n",
              "428909                                0.000906  0.999309           0.000164   \n",
              "428910                                0.001056  1.000229           0.000172   \n",
              "428911                                0.000301  0.999461           0.000154   \n",
              "428912                                0.000302  1.001094           0.000181   \n",
              "\n",
              "        bid_spread_mean  ask_spread_mean  volume_imbalance_mean  \\\n",
              "0             -0.000231         0.000423             205.157609   \n",
              "1             -0.000088         0.000199             116.313783   \n",
              "2             -0.000095         0.000176             115.274576   \n",
              "3             -0.000101         0.000185             174.898058   \n",
              "4             -0.000087         0.000165             148.091667   \n",
              "...                 ...              ...                    ...   \n",
              "428908        -0.000151         0.000151             357.053830   \n",
              "428909        -0.000151         0.000151             631.287109   \n",
              "428910        -0.000151         0.000151             386.595238   \n",
              "428911        -0.000151         0.000151             994.640777   \n",
              "428912        -0.000151         0.000151             445.455969   \n",
              "\n",
              "        total_volume_mean  neighbor_vol_1  neighbor_vol_2  neighbor_vol_3  \n",
              "0              498.081522        0.006266        0.005423        0.003780  \n",
              "1              382.923754        0.002395        0.004334        0.003503  \n",
              "2              319.016949        0.003481        0.003443        0.001790  \n",
              "3              496.927184        0.001958        0.003481        0.003590  \n",
              "4              482.441667        0.001628        0.002264        0.001196  \n",
              "...                   ...             ...             ...             ...  \n",
              "428908        2268.246377        0.001007        0.000905        0.001274  \n",
              "428909        2172.791016        0.001670        0.001790        0.001905  \n",
              "428910        1867.503968        0.001569        0.001595        0.001367  \n",
              "428911        3326.633010        0.001466        0.001355        0.001246  \n",
              "428912        2089.162427        0.001784        0.001616        0.001367  \n",
              "\n",
              "[428913 rows x 46 columns]"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuJ6YpphCGdq"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmspe(y_true, y_pred):\n",
        "    mask = y_true != 0\n",
        "    rmspe = np.sqrt(np.mean(np.square((y_true[mask] - y_pred[mask]) / y_true[mask])))\n",
        "    return rmspe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def rmspe(y_true, y_pred):\n",
        "    mask = y_true != 0\n",
        "    rmspe = np.sqrt(np.mean(np.square((y_true[mask] - y_pred[mask]) / y_true[mask])))\n",
        "    return rmspe\n",
        "\n",
        "def lgb_rmspe(y_pred, data):\n",
        "    y_true = data.get_label()\n",
        "    rmspe_val = rmspe(y_true, y_pred)\n",
        "    return 'RMSPE', rmspe_val, False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = {\n",
        "    'learning_rate': 0.1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',  # Assuming a regression problem; adjust as needed\n",
        "    'metric': 'None',  # Use 'None' to use custom metric only\n",
        "    'num_leaves': 31,\n",
        "    'verbose': -1,\n",
        "    'seed': 42,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = master.drop(columns=['row_id', 'target'])\n",
        "y = master['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_train = lgb.Dataset(X_train, label=y_train)\n",
        "d_valid = lgb.Dataset(X_test, label=y_test, reference=d_train)\n",
        "\n",
        "clf = lgb.train(\n",
        "    params,\n",
        "    d_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[d_train, d_valid],\n",
        "    valid_names=['train', 'valid'],\n",
        "    feval=lgb_rmspe,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSPE: 0.2511232379160162\n"
          ]
        }
      ],
      "source": [
        "y_pred = clf.predict(X_test, num_iteration=clf.best_iteration)\n",
        "print(\"RMSPE:\", rmspe(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-07 12:46:39,921] A new study created in memory with name: no-name-a8e7e538-6329-4f44-aac3-9cff0f3e1492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2024-02-07 12:47:16,255] Trial 0 finished with value: 0.25701960768665577 and parameters: {'num_leaves': 287, 'learning_rate': 0.2418696704745987, 'n_estimators': 879, 'min_child_samples': 52}. Best is trial 0 with value: 0.25701960768665577.\n",
            "[I 2024-02-07 12:47:46,973] Trial 1 finished with value: 0.24880682863590486 and parameters: {'num_leaves': 148, 'learning_rate': 0.05525245094839312, 'n_estimators': 858, 'min_child_samples': 61}. Best is trial 1 with value: 0.24880682863590486.\n",
            "[I 2024-02-07 12:48:20,781] Trial 2 finished with value: 0.2507982579469728 and parameters: {'num_leaves': 86, 'learning_rate': 0.029151163586629544, 'n_estimators': 1164, 'min_child_samples': 45}. Best is trial 1 with value: 0.24880682863590486.\n",
            "[I 2024-02-07 12:50:09,255] Trial 3 finished with value: 0.24660080495969217 and parameters: {'num_leaves': 55, 'learning_rate': 0.11604233408218217, 'n_estimators': 7405, 'min_child_samples': 22}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 12:52:16,991] Trial 4 finished with value: 0.2616125780389114 and parameters: {'num_leaves': 97, 'learning_rate': 0.2886011018612287, 'n_estimators': 6398, 'min_child_samples': 67}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 12:53:14,389] Trial 5 finished with value: 0.26451434975327925 and parameters: {'num_leaves': 266, 'learning_rate': 0.24045603507055174, 'n_estimators': 1756, 'min_child_samples': 7}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 12:57:11,782] Trial 6 finished with value: 0.247486431915543 and parameters: {'num_leaves': 176, 'learning_rate': 0.050794684029643995, 'n_estimators': 7276, 'min_child_samples': 73}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 12:58:59,694] Trial 7 finished with value: 0.2509404869545466 and parameters: {'num_leaves': 21, 'learning_rate': 0.018781533317915315, 'n_estimators': 6774, 'min_child_samples': 95}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:02:18,152] Trial 8 finished with value: 0.25739091131601394 and parameters: {'num_leaves': 223, 'learning_rate': 0.17202881625632416, 'n_estimators': 3935, 'min_child_samples': 79}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:06:05,844] Trial 9 finished with value: 0.2660333801487236 and parameters: {'num_leaves': 267, 'learning_rate': 0.27028572489316405, 'n_estimators': 4845, 'min_child_samples': 68}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:08:04,210] Trial 10 finished with value: 0.24954934004532217 and parameters: {'num_leaves': 29, 'learning_rate': 0.12282075136511614, 'n_estimators': 9947, 'min_child_samples': 23}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:12:19,797] Trial 11 finished with value: 0.2480058626081883 and parameters: {'num_leaves': 181, 'learning_rate': 0.10571498704012745, 'n_estimators': 8593, 'min_child_samples': 36}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:15:03,590] Trial 12 finished with value: 0.2476540196691728 and parameters: {'num_leaves': 142, 'learning_rate': 0.08435195724739586, 'n_estimators': 7766, 'min_child_samples': 5}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:17:59,941] Trial 13 finished with value: 0.25540090316897707 and parameters: {'num_leaves': 202, 'learning_rate': 0.1623817872864978, 'n_estimators': 5936, 'min_child_samples': 27}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:21:58,118] Trial 14 finished with value: 0.2494396460123792 and parameters: {'num_leaves': 103, 'learning_rate': 0.07300962111373098, 'n_estimators': 8950, 'min_child_samples': 89}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:23:04,651] Trial 15 finished with value: 0.24849799285461688 and parameters: {'num_leaves': 64, 'learning_rate': 0.12890728514445485, 'n_estimators': 3379, 'min_child_samples': 81}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:26:38,874] Trial 16 finished with value: 0.25313779778639156 and parameters: {'num_leaves': 133, 'learning_rate': 0.1718129140919979, 'n_estimators': 7598, 'min_child_samples': 19}. Best is trial 3 with value: 0.24660080495969217.\n",
            "[I 2024-02-07 13:30:46,770] Trial 17 finished with value: 0.24641373593233606 and parameters: {'num_leaves': 234, 'learning_rate': 0.04371432460786574, 'n_estimators': 5173, 'min_child_samples': 40}. Best is trial 17 with value: 0.24641373593233606.\n",
            "[I 2024-02-07 13:33:57,514] Trial 18 finished with value: 0.25991301074687767 and parameters: {'num_leaves': 234, 'learning_rate': 0.20623646682065985, 'n_estimators': 5001, 'min_child_samples': 38}. Best is trial 17 with value: 0.24641373593233606.\n",
            "[I 2024-02-07 13:34:56,367] Trial 19 finished with value: 0.24712933278543853 and parameters: {'num_leaves': 63, 'learning_rate': 0.09557095635045335, 'n_estimators': 2878, 'min_child_samples': 32}. Best is trial 17 with value: 0.24641373593233606.\n",
            "[I 2024-02-07 13:37:20,071] Trial 20 finished with value: 0.2551939803459193 and parameters: {'num_leaves': 230, 'learning_rate': 0.13784719396926218, 'n_estimators': 4587, 'min_child_samples': 15}. Best is trial 17 with value: 0.24641373593233606.\n",
            "[I 2024-02-07 13:38:17,773] Trial 21 finished with value: 0.24611443099524308 and parameters: {'num_leaves': 56, 'learning_rate': 0.09167589021982049, 'n_estimators': 2983, 'min_child_samples': 31}. Best is trial 21 with value: 0.24611443099524308.\n",
            "[I 2024-02-07 13:38:59,097] Trial 22 finished with value: 0.24604964127747822 and parameters: {'num_leaves': 50, 'learning_rate': 0.051724111286829896, 'n_estimators': 2462, 'min_child_samples': 46}. Best is trial 22 with value: 0.24604964127747822.\n",
            "[I 2024-02-07 13:40:01,632] Trial 23 finished with value: 0.24325816160848657 and parameters: {'num_leaves': 123, 'learning_rate': 0.04743008092032521, 'n_estimators': 2355, 'min_child_samples': 46}. Best is trial 23 with value: 0.24325816160848657.\n",
            "[I 2024-02-07 13:41:06,177] Trial 24 finished with value: 0.2458895811726859 and parameters: {'num_leaves': 123, 'learning_rate': 0.06920892197344669, 'n_estimators': 2334, 'min_child_samples': 53}. Best is trial 23 with value: 0.24325816160848657.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials: 25\n",
            "Best trial: {'num_leaves': 123, 'learning_rate': 0.04743008092032521, 'n_estimators': 2355, 'min_child_samples': 46}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmspe',  # Make sure to define or adjust the metric as needed\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 10000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'seed': 42,\n",
        "    }\n",
        "    \n",
        "    # Assuming X_train, X_test, y_train, y_test are predefined\n",
        "    d_train = lgb.Dataset(X_train, label=y_train)\n",
        "    gbm = lgb.train(param, d_train)\n",
        "    preds = gbm.predict(X_test)\n",
        "    return rmspe(y_test, preds)  # Use your custom rmspe function\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=25)\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = filtered_master.drop(columns=['row_id', 'target'])\n",
        "y = filtered_master['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_model = KNeighborsRegressor(n_neighbors=25)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_predictions = knn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Squared Percentage Error: 0.29777873808461747\n"
          ]
        }
      ],
      "source": [
        "knn_rmspe = rmspe(y_test, knn_predictions)\n",
        "print(f'Root Mean Squared Percentage Error: {knn_rmspe}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = filtered_master.drop(columns=['row_id', 'target'])\n",
        "y = filtered_master['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "linear_predictions = linear_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression RMSPE: 0.2913722425547761\n"
          ]
        }
      ],
      "source": [
        "linear_rmspe = rmspe(y_test, linear_predictions)\n",
        "print(f'Linear Regression RMSPE: {linear_rmspe}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = filtered_master.drop(columns=['row_id', 'target'])\n",
        "y = filtered_master['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "rf_predictions = random_forest_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest RMSPE: 0.27258505567872915\n"
          ]
        }
      ],
      "source": [
        "rf_rmspe = rmspe(y_test, rf_predictions)\n",
        "print(f'Random Forest RMSPE: {rf_rmspe}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = filtered_master.drop(columns=['row_id', 'target'])\n",
        "y = filtered_master['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradient_boosting_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "gb_predictions = gradient_boosting_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting RMSPE: 0.2687369762052166\n"
          ]
        }
      ],
      "source": [
        "gb_rmspe = rmspe(y_test, gb_predictions)\n",
        "print(f'Gradient Boosting RMSPE: {gb_rmspe}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = filtered_master.drop(columns=['row_id', 'target'])\n",
        "y = filtered_master['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svr_model = SVR()\n",
        "svr_model.fit(X_train, y_train)\n",
        "svr_predictions = svr_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVR RMSPE: 11.245415973325791\n"
          ]
        }
      ],
      "source": [
        "svr_rmspe = rmspe(y_test, svr_predictions)\n",
        "print(f'SVR RMSPE: {svr_rmspe}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr1GzUS93Ufg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%jupyter` not found.\n"
          ]
        }
      ],
      "source": [
        "# %%shell\n",
        "# jupyter nbconvert --to html /content/milestone4.ipynb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DCqMjbuQ1yhB",
        "U6gZlJILpStt",
        "3oBkUzxmtzAl",
        "ObRgMeHASM-B",
        "xLeoQqC8mJa1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
